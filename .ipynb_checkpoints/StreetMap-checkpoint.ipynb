{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** DA3 OPEN STREET MAP - DATA WRANGLING WITH MONGODB***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Map Area: Berlin, Germany*\n",
    "\n",
    "https://www.openstreetmap.org/#map=13/52.5180/13.4076\n",
    "\n",
    "The area contains the central area of Berlin. As it is one of the biggest cities in Europe, we can expect a lot of additional information about this area from the osm project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sample of nodes in an .osm file:\n",
    "\n",
    "<node id=\"302864488\" visible=\"true\" version=\"7\" changeset=\"36059354\" timestamp=\"2015-12-20T06:35:42Z\" user=\"atpl_pilot\" uid=\"881429\" lat=\"52.5259586\" lon=\"13.3894424\">\n",
    "  <tag k=\"addr:city\" v=\"Berlin\"/>\n",
    "  <tag k=\"addr:country\" v=\"DE\"/>\n",
    "  <tag k=\"addr:housenumber\" v=\"45\"/>\n",
    "  <tag k=\"addr:postcode\" v=\"10117\"/>\n",
    "  <tag k=\"addr:street\" v=\"Oranienburger Straße\"/>\n",
    "  <tag k=\"addr:suburb\" v=\"Mitte\"/>\n",
    "  <tag k=\"amenity\" v=\"restaurant\"/>\n",
    "  <tag k=\"contact:phone\" v=\"+493028040505\"/>\n",
    "  <tag k=\"cuisine\" v=\"cuban\"/>\n",
    "  <tag k=\"name\" v=\"QBA\"/>\n",
    "  <tag k=\"website\" v=\"http://www.qba-restaurant.de/\"/>\n",
    "  <tag k=\"wheelchair\" v=\"no\"/>\n",
    " </node>\n",
    " \n",
    " <way id=\"5090250\" visible=\"true\" timestamp=\"2009-01-19T19:07:25Z\" version=\"8\" changeset=\"816806\" user=\"Blumpsy\" uid=\"64226\">\n",
    "    <nd ref=\"822403\"/>\n",
    "    <nd ref=\"21533912\"/>\n",
    "    <nd ref=\"821601\"/>\n",
    "    <nd ref=\"21533910\"/>\n",
    "    <nd ref=\"135791608\"/>\n",
    "    <nd ref=\"333725784\"/>\n",
    "    <nd ref=\"333725781\"/>\n",
    "    <nd ref=\"333725774\"/>\n",
    "    <nd ref=\"333725776\"/>\n",
    "    <nd ref=\"823771\"/>\n",
    "    <tag k=\"highway\" v=\"residential\"/>\n",
    "    <tag k=\"name\" v=\"Clipstone Street\"/>\n",
    "    <tag k=\"oneway\" v=\"yes\"/>\n",
    "  </way>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "#https://www.openstreetmap.org/export#map=13/52.5180/13.4076\n",
    "OSM_FILE = 'berlin_map.osm'\n",
    "SAMPLE_FILE = 'berlin_map_reduced.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSMSize 154.6 MB\n"
     ]
    }
   ],
   "source": [
    "#check file size\n",
    "#resource: http://stackoverflow.com/questions/2104080/how-to-check-file-size-in-python\n",
    "\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "    \n",
    "size = file_size(OSM_FILE)\n",
    "print ('OSMSize', size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create sample file with the k - th size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berlin_map.osm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "k = 14 # Parameter: take every k-th top level element\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    b = bytearray()\n",
    "    b.extend('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'.encode())\n",
    "    b.extend('<osm>\\n  '.encode())\n",
    "    output.write(b)\n",
    "\n",
    "    # Write every kth top level element\n",
    "    print (OSM_FILE)\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "\n",
    "        if not i % k:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "    b_end = bytearray()\n",
    "    b_end.extend('</osm>'.encode())\n",
    "    output.write(b_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleSize 11.3 MB\n"
     ]
    }
   ],
   "source": [
    "#check size of sample file\n",
    "sample_size = file_size(SAMPLE_FILE)\n",
    "print ('SampleSize', sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDITING THE .OSM FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE USERS:  2003\n",
      "NODES: 594858\n",
      "WAYS: 86201\n",
      "RELATIONS 3203\n"
     ]
    }
   ],
   "source": [
    "#get benchmark data\n",
    "\"\"\"\n",
    "    Reference:\n",
    "    https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075462/lessons/768058569/concepts/8426285720923#\n",
    "\"\"\"\n",
    "def get_benchmark_data(filename):\n",
    "    users = set()\n",
    "    count_nodes = 0\n",
    "    count_ways = 0\n",
    "    count_relations = 0\n",
    "    \n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.tag == 'node':\n",
    "            count_nodes += 1\n",
    "            user = element.attrib['uid']\n",
    "            if user in users:\n",
    "                pass\n",
    "            else:\n",
    "                users.add(user)\n",
    "        if element.tag == 'way':\n",
    "            count_ways += 1\n",
    "        if element.tag == 'relation':\n",
    "            count_relations += 1\n",
    "    return users, count_nodes, count_ways, count_relations\n",
    "\n",
    "users, count_nodes, count_ways, count_relations = get_benchmark_data(OSM_FILE)\n",
    "\n",
    "print ('UNIQUE USERS: ', len(users))\n",
    "print ('NODES:', count_nodes)\n",
    "print ('WAYS:', count_ways)\n",
    "print ('RELATIONS', count_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDIT STREET NAMES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problems encounterd while auditing street names:*\n",
    "\n",
    "   In German language there a lot of different namings and writings for streets: For example a 'Straße' can be 'Auerstraße' or     'Antwerpener Straße' or 'Alfred-Jung-Straße' or 'Straße des 17. Juni'. This happens also to other street types, like              '*weg*', '*zeile*', '*platz*' and also for streets that are or used to be near rivers like: '*damm*', '*ufer*', '*graben*'.\n",
    "   Because there a lot of bridges in Berlin, bridges belong to ways *brücke*. \n",
    "   A street name starting with 'Zur ', 'Am ' or 'An ' simply means 'at ', but is also a valid street name. \n",
    "    \n",
    "   Another problem is the case sensitiveness. Those key words may be written with uppercase or lowercase. In our case we simply    transform it to lowercase, to audit the street names. \n",
    "    \n",
    "   Another problem are the german Umlaute. Because we don't wan't to get troubled, instead of using regex, we will use a simple    loop to audit the street names.\n",
    "    \n",
    "   A further task would be to transform all Umlaute of the file at the beginning, to make sure not to get in trouble later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of different street types in Berlin\n",
      "Straße : 620\n",
      "Platz : 48\n",
      "Ufer : 28\n",
      "Allee : 18\n",
      "Damm : 12\n",
      "Weg : 9\n",
      "Am : 8\n",
      "Park : 6\n",
      "An : 5\n",
      "Graben : 4\n",
      "Brücke : 4\n",
      "Zeile : 3\n",
      "Markt : 3\n",
      "Promenade : 3\n",
      "Hof : 2\n",
      "Stadtbahnbogen : 1\n",
      "Dohnagestell : 1\n",
      "Südstern : 1\n",
      "Unter Den Linden : 1\n",
      "Südring : 1\n",
      "Alt-Moabit : 1\n",
      "Wriezener Karree : 1\n",
      "Zur Börse : 1\n",
      "Alt-Stralau : 1\n",
      "Viehtrift : 1\n",
      "Fischerinsel : 1\n",
      "Vor Dem Schlesischen Tor : 1\n",
      "In Den Ministergärten : 1\n",
      "Steg : 1\n",
      "Prenzlauer Berg : 1\n",
      "Südpassage : 1\n",
      "Zur Innung : 1\n",
      "Hinter Der Katholischen Kirche : 1\n",
      "Neue Welt : 1\n",
      "Fischzug : 1\n",
      "Zur Waage : 1\n",
      "Großer Stern : 1\n",
      "Westring : 1\n"
     ]
    }
   ],
   "source": [
    "'''reference:\n",
    "https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075462/lessons/768058569/concepts/8755386150923#'''\n",
    "\n",
    "#start with lower case letters, due to different ways of writing street names in german\n",
    "expected = ['straße', 'platz', 'gasse', 'weg', 'allee', 'damm', 'ufer', 'graben', 'brücke', \n",
    "            'promenade', 'park', 'am', 'an', 'markt', 'steg', 'hof', 'zeile']\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    found = False\n",
    "    for e in expected:\n",
    "        if e in street_name.lower():\n",
    "            found = True\n",
    "            break\n",
    "           \n",
    "    if found:\n",
    "        street_types[e].add(street_name)\n",
    "    else:\n",
    "        street_types[street_name.title()].add(street_name)    \n",
    "                              \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "#audit the street names\n",
    "def audit_street_names(osmfile):\n",
    "    osm_file = open(osmfile, 'rt', encoding='utf-8')\n",
    "    #set is a list without duplicates\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    print('Numbers of different street types in Berlin')\n",
    "    pretty_print(street_types)\n",
    "\n",
    "def pretty_print(d):\n",
    "    for sorted_key in sorted(d, key=lambda k: len(d[k]), reverse=True):\n",
    "        v = d[k]\n",
    "        print (sorted_key.title(), ':', len(d[sorted_key]))\n",
    "        \n",
    "audit_street_names(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It seems that all street names are valid!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Audit postal codes and suburbs**\n",
    "\n",
    "Audit Post codes and suburbs The postal code in Berlin ranges from 10115 to 14199 In the following task we want to check if the postal code is valid for Berlin and if it matches with the suburb according to thist list : https://en.wikipedia.org/wiki/List_of_postal_codes_in_Germany#Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suburbs_with_postal_codes = {\n",
    "                            'Mitte': [10115, 10117, 10119, 10178, 10179],\n",
    "                             'Gesundbrunnen': [13347, 13353, 13355, 13357, 13359, 13409],\n",
    "                             'Friedrichshain': [10243, 10245, 10247, 10249],\n",
    "                             'Prenzlauer Berg': [10405, 10407, 10409, 10435, 10437, 10439, 10369],\n",
    "                             'Kreuzberg': [10961, 10963, 10965, 10967, 10969, 10997, 10999],\n",
    "                             'Tiergarten': [10551, 10553, 10785, 10787, 10559, 10555, 10557],\n",
    "                             'Charlottenburg': [10585, 10587, 10589, 10623, 10625, 10627, 10629],\n",
    "                             'Wilmersdorf': [10707, 10709, 10711, 10713, 10715, 10719, 10717],\n",
    "                             'Tempelhof': [10777, 10779, 10781, 10783, 10789],\n",
    "                             'Schöneberg': [10823, 10825, 10827, 10829, 10717, 10783],\n",
    "                             'Neukölln': [12043, 12045, 12047, 12049, 12051, 12053, 12055, 12057, 12059],\n",
    "                             'Steglitz': [12157, 12161, 12163, 12165, 12167, 12169],\n",
    "                             'Lichterfelde': [12203, 12205, 12207, 12209],\n",
    "                             'Wedding': [13347, 13349, 13351, 13353, 13355, 13357, 13359],\n",
    "                             'Reinickendorf': [13403, 13405, 13407, 13409],\n",
    "                             'Lichtenberg': [13055, 13053, 10365, 10367, 10317],\n",
    "                             'Pankow': [13187, 13189],\n",
    "                             'Zehlendorf': [14163, 14165, 14167, 14169],\n",
    "                             'Wannsee': [14109],\n",
    "                             'Wittenau': [13435, 13437, 13439],\n",
    "                             'Weißensee': [13086, 13088, 13089],\n",
    "                             'Mahrzahn': [12679, 12681, 12683, 12685, 12687, 12689],\n",
    "                             'Köpenick': [12555, 12557, 12559, 12587, 12435],\n",
    "                             'Adlershof': [12487, 12489],\n",
    "                             'Lichtenrade': [12305, 12307, 12309],\n",
    "                             'Marienfelde': [12277, 12279],\n",
    "                             'Lankwitz': [12247, 12249]\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "#create a list with all postal codes\n",
    "all_postal_codes = set()\n",
    "for v in suburbs_with_postal_codes.values():\n",
    "    for v_ in v:\n",
    "        all_postal_codes.add(v_)\n",
    "#create a list to output wrong postal codes    \n",
    "wrong_postal_codes = set()\n",
    "\n",
    "#check if postal code is correct and then check if it corresponds to correct suburbs\n",
    "def audit_postal_code(postal_code):\n",
    "    if int(postal_code) not in all_postal_codes:\n",
    "        wrong_postal_codes.add(int(postal_code))\n",
    "        \n",
    "def is_postal_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_postal_codes(osmfile):\n",
    "    osm_file = open(osmfile, 'rb')\n",
    "    #set is a list without duplicates\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postal_code(tag):\n",
    "                    audit_postal_code(tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "\n",
    "audit_postal_codes(OSM_FILE)\n",
    "print (wrong_postal_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All postal codes are correct!\n",
    "\n",
    "Now we want to check our suburbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Plänterwald', 'Moabit', 'Alt-Hohenschönhausen', 'Rummelsburg', 'Fennpfuhl', 'Friedrichsfelde', 'Hansaviertel', 'Alt-Treptow'}\n"
     ]
    }
   ],
   "source": [
    "all_suburbs = set()\n",
    "for v in suburbs_with_postal_codes.keys():\n",
    "    all_suburbs.add(v)\n",
    "#create a list to output wrong postal codes    \n",
    "wrong_suburbs = set()\n",
    "\n",
    "def audit_suburbs(osmfile):\n",
    "    osm_file = open(osmfile, 'rb')\n",
    "    #set is a list without duplicates\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_suburb(tag):\n",
    "                    audit_suburb(tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "\n",
    "def audit_suburb(suburb):\n",
    "    if (suburb) not in all_suburbs:\n",
    "        wrong_suburbs.add(suburb)    \n",
    "    \n",
    "def is_suburb(elem):\n",
    "    return (elem.attrib['k'] == \"addr:suburb\")\n",
    "\n",
    "audit_suburbs(SAMPLE_FILE)\n",
    "print (wrong_suburbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uhh. There are some neighbourhoods that aren't suburbs.\n",
    "\n",
    "Fennpfuhl, Alt-Hohenschönhausen, Friedrichsfelde and Rummelsburg are neighbourhoods in Lichtenberg.\n",
    "Moabit and the Hansaviertel are neighbourhoods in Tiergarten.\n",
    "Alt-Treptow and Plänterwald are neighbourhoods in Köpenick.\n",
    "\n",
    "We will map these neighbourhoods to the corresponding suburbs before saving them to the mongoDB.\n",
    "\n",
    "In the next step we want to see if postal codes are correct for the corresponding suburb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'Plänterwald': 12435, 'Friedrichshain': 10245, 'Weißensee': 13088, 'Tiergarten': 10785, 'Rummelsburg': 10317, 'Pankow': 10439, 'Hansaviertel': 10555, 'Lichtenberg': 10367, 'Alt-Treptow': 12435, 'Mitte': 10115, 'Charlottenburg-Wilmersdorf': 10623, 'Lichtenrade': 10777, 'Prenzlauer Berg': 10405, 'Schöneberg': 10787, 'Moabit': 10559, 'Alt-Hohenschönhausen': 13055, 'Friedrichsfelde': 10245, 'Gesundbrunnen': 13357, 'Neukölln': 12045, 'Fennpfuhl': 10367, 'Wedding': 13351, 'Kreuzberg': 10969, 'Charlottenburg': 10623, 'Wilmersdorf': 10789})\n"
     ]
    }
   ],
   "source": [
    "#check if postal code and suburb are correct\n",
    "check_suburbs_and_postal_codes = defaultdict(set)\n",
    "    \n",
    "def audit_postal_code_and_suburb(osmfile):\n",
    "    osm_file = open(osmfile, 'rb')\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        current_suburb = None\n",
    "        current_postal_code = None\n",
    "        if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_suburb(tag):\n",
    "                    current_suburb = tag.attrib['v']\n",
    "                if is_postal_code(tag):\n",
    "                    current_postal_code = tag.attrib['v']\n",
    "        if current_postal_code and current_suburb:        \n",
    "            check_suburbs_and_postal_codes[current_suburb] = int(current_postal_code)                             \n",
    "    osm_file.close()\n",
    "\n",
    "audit_postal_code_and_suburb(OSM_FILE) \n",
    "print (check_suburbs_and_postal_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no suburb named Plänterwald\n",
      "no suburb named Rummelsburg\n",
      "Pankow 10439 [13187, 13189]\n",
      "no suburb named Hansaviertel\n",
      "no suburb named Alt-Treptow\n",
      "no suburb named Charlottenburg-Wilmersdorf\n",
      "Lichtenrade 10777 [12305, 12307, 12309]\n",
      "Schöneberg 10787 [10823, 10825, 10827, 10829, 10717, 10783]\n",
      "no suburb named Moabit\n",
      "no suburb named Alt-Hohenschönhausen\n",
      "no suburb named Friedrichsfelde\n",
      "no suburb named Fennpfuhl\n",
      "Wilmersdorf 10789 [10707, 10709, 10711, 10713, 10715, 10719, 10717]\n"
     ]
    }
   ],
   "source": [
    "def check_check(a, b):\n",
    "    #check if key, value also exist in key and value array\n",
    "    for key in a:\n",
    "        if key in b:\n",
    "            first, second = a[key], b[key]\n",
    "            if first in second:\n",
    "                pass\n",
    "            else:\n",
    "                print(key, first, second)\n",
    "        else:\n",
    "            print ('no suburb named', key)\n",
    "            \n",
    "check_check(check_suburbs_and_postal_codes, suburbs_with_postal_codes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrong suburbs from above, where already found in the audit_suburbs(). And we found Charlottenburg-Wilmersdorf, this value combines two suburbs.These are going to be corrected later.\n",
    "There are some suburbs that don't match with our postal codes.\n",
    "In a next step we could check the exact address and find out if the postal code or the suburb is wrong. Or both.\n",
    "But for now it looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "reference:\n",
    "https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075462/lessons/768058569/concepts/8755386150923#'''\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "BICYCLE_WAYS = [\"cycleway\", \"bicycle_road\", \"bicycle\"]\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    created_dict = {}\n",
    "    pos_list = []\n",
    "    long = 0\n",
    "    lat = 0\n",
    "    address_dict = {}\n",
    "    bicycle_way = False\n",
    "\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :      \n",
    "        node[\"type\"] = element.tag\n",
    "        for name, value in element.items():\n",
    "            if name in CREATED:\n",
    "                created_dict[name] = value\n",
    "            elif name == 'long':\n",
    "                lon = float(value)\n",
    "            elif name == 'lat':\n",
    "                lat = float(value)\n",
    "            else:\n",
    "                node[name] = value\n",
    "\n",
    "            if len(created_dict):\n",
    "                node[\"created\"] = created_dict\n",
    "            if lat:\n",
    "                pos_list.append(lat)\n",
    "            if long:\n",
    "                pos_list.append(long)\n",
    "            if len(pos_list):\n",
    "                node[\"pos\"] = pos_list\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            k = tag.attrib['k']\n",
    "            v = tag.attrib['v']\n",
    "            \n",
    "            #get all bicycle ways, the german and the english values\n",
    "            if k in BICYCLE_WAYS and value != \"no\":\n",
    "                bicycle_way = True\n",
    "            #get the address   \n",
    "            if k == 'addr:suburb':\n",
    "                address_dict['suburb'] = update_suburbs(v, mapping_suburbs)\n",
    "            elif k == 'addr:postcode':\n",
    "                address_dict['postal_code'] = v\n",
    "            elif k == 'addr:street':\n",
    "                address_dict['street'] = v\n",
    "            elif k == 'addr:housenumber':\n",
    "                address_dict['housenumber'] = v\n",
    "            elif k == 'addr:country':\n",
    "                pass\n",
    "            elif k == 'addr:city':\n",
    "                pass \n",
    "            elif problemchars.search(k):\n",
    "                pass\n",
    "            else: node[k] = v                 \n",
    "                \n",
    "        node_refs_list = []\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            node_refs_list.append(nd.attrib['ref'])\n",
    "        if len(node_refs_list):\n",
    "            node[\"node_refs\"] = node_refs_list\n",
    "        \n",
    "        if bicycle_way is True: \n",
    "            node['bicycle_way'] = 'Yes'\n",
    "        if len(address_dict):\n",
    "            node['address'] = address_dict\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "                \n",
    "#fix suburbs before exporting to mongoDB\n",
    "mapping_suburbs = { \"Alt-Treptow\": \"Köpenick\",\n",
    "                    \"Moabit\": \"Tiergarten\",\n",
    "                    \"Hansaviertel\": \"Tiergarten\",\n",
    "                    \"Fennpfuhl\": \"Lichtenberg\",\n",
    "                    \"Alt-Hohenschönhausen\": \"Lichtenberg\",\n",
    "                    \"Rummelsburg\": \"Lichtenberg\",\n",
    "                    \"Plänterwald\": \"Köpenick\",\n",
    "                    \"Charlottenburg-Wilmersdorf\": \"Charlottenburg\" }\n",
    "\n",
    "def update_suburbs(suburb, mapping_suburbs):\n",
    "    for key, value in mapping_suburbs.items():\n",
    "        if suburb == key:\n",
    "            suburb = value\n",
    "    return suburb\n",
    "\n",
    "def process_map(file_in):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            \n",
    "            if el:\n",
    "                data.append(el)\n",
    "                fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "data = process_map('berlin_map.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show first five elements of the generated .json data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lon': '13.4477657', 'pos': [52.5265215, 52.5265215, 52.5265215], 'created': {'timestamp': '2015-07-19T12:27:05Z', 'uid': '1439784', 'version': '6', 'user': 'der-martin', 'changeset': '32731923'}, 'id': '12614600', 'type': 'node'}, {'lon': '13.4816429', 'pos': [52.512938, 52.512938, 52.512938], 'created': {'timestamp': '2015-12-06T19:23:44Z', 'uid': '43566', 'version': '9', 'user': 'anbr', 'changeset': '35793006'}, 'id': '12614606', 'type': 'node'}, {'lon': '13.4287152', 'pos': [52.5375413, 52.5375413, 52.5375413], 'created': {'timestamp': '2015-11-15T08:45:31Z', 'uid': '43566', 'version': '12', 'user': 'anbr', 'changeset': '35323067'}, 'id': '12614644', 'type': 'node'}, {'lon': '13.4444757', 'pos': [52.5295609, 52.5295609, 52.5295609], 'created': {'timestamp': '2016-08-31T19:16:25Z', 'uid': '43566', 'version': '4', 'user': 'anbr', 'changeset': '41833634'}, 'id': '12614650', 'type': 'node'}, {'lon': '13.4696325', 'pos': [52.5141418, 52.5141418, 52.5141418], 'created': {'timestamp': '2014-06-15T15:19:01Z', 'uid': '43566', 'version': '10', 'user': 'anbr', 'changeset': '22946433'}, 'id': '12614651', 'type': 'node'}]\n"
     ]
    }
   ],
   "source": [
    "example = data[:5]\n",
    "print (example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save data to mongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lon': '13.4477657', '_id': ObjectId('587f2bf3c7993a32c49f991e'), 'type': 'node', 'pos': [52.5265215, 52.5265215, 52.5265215], 'created': {'timestamp': '2015-07-19T12:27:05Z', 'uid': '1439784', 'changeset': '32731923', 'user': 'der-martin', 'version': '6'}, 'id': '12614600'}\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "db = client.berlin\n",
    "\n",
    "def insert_osm_data(infile, db):\n",
    "    db.berlin.drop()      \n",
    "    #import data into a collection named \"berlin\"\n",
    "    db.berlin.insert_many(infile)\n",
    "    print (db.berlin.find_one())\n",
    "\n",
    "insert_osm_data(data, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (len(db.berlin.distinct(\"created\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":( distinct works only up to 16mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get statistics of our database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataSize': 192994830.0, 'avgObjSize': 283.3746121848474, 'collections': 1, 'numExtents': 0, 'storageSize': 62980096.0, 'db': 'berlin', 'objects': 681059, 'ok': 1.0, 'views': 0, 'indexes': 1, 'indexSize': 5992448.0}\n"
     ]
    }
   ],
   "source": [
    "stats = (db.command(\"dbstats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Collection\n",
      "60.1 MB\n"
     ]
    }
   ],
   "source": [
    "print ('Size of Collection')\n",
    "print (convert_bytes(62980096.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count unique users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2277\n"
     ]
    }
   ],
   "source": [
    "print (len(db.berlin.distinct(\"created.user\")));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_print_list(d):\n",
    "    for member in d:\n",
    "        print (member['_id'], ':', member['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Count entries for suburbs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries for suburbs:\n",
      "Mitte : 7513\n",
      "Prenzlauer Berg : 6303\n",
      "Kreuzberg : 6100\n",
      "Friedrichshain : 5866\n",
      "Tiergarten : 4407\n",
      "Lichtenberg : 3032\n",
      "Schöneberg : 2943\n",
      "Wedding : 1293\n",
      "Gesundbrunnen : 1240\n",
      "Köpenick : 588\n",
      "Neukölln : 581\n",
      "Wilmersdorf : 546\n",
      "Charlottenburg : 481\n",
      "Weißensee : 324\n",
      "Pankow : 1\n",
      "Lichtenrade : 1\n",
      "Friedrichsfelde : 1\n"
     ]
    }
   ],
   "source": [
    "# get top ten of contributing users\n",
    "def count_entries_by_suburbs():\n",
    "    pipeline = [{'$match': {'address.suburb': {'$exists': 1}}},\n",
    "                {'$group' : { '_id' : '$address.suburb', 'count' : {'$sum' : 1}}},       \n",
    "                {'$sort': {'count': -1}}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.berlin.aggregate(pipeline)]\n",
    "\n",
    "pipeline = count_entries_by_suburbs()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Entries for suburbs:')\n",
    "pretty_print_list(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 contributiong users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 contributing users with counted entries:\n",
      "atpl_pilot : 246334\n",
      "MorbZ : 48504\n",
      "Bot45715 : 34936\n",
      "anbr : 34122\n",
      "toaster : 19297\n",
      "Polarbear : 13495\n",
      "Berliner Igel : 13286\n",
      "Shmias : 10802\n",
      "wicking : 8506\n",
      "Elwood : 8266\n"
     ]
    }
   ],
   "source": [
    "# get top ten of contributing users\n",
    "def get_top_ten_users():\n",
    "    pipeline = [{'$group' : { '_id' : '$created.user', 'count' : {'$sum' : 1}}},       \n",
    "                {'$sort': {'count': -1}},\n",
    "                { '$limit': 10}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.berlin.aggregate(pipeline)]\n",
    "\n",
    "pipeline = get_top_ten_users()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Top 10 contributing users with counted entries:')\n",
    "pretty_print_list(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get an overview of different types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different Types:\n",
      "node : 594822\n",
      "way : 86165\n",
      "multipolygon : 30\n",
      "Schrank : 22\n",
      "property_line : 4\n",
      "kiosk : 2\n",
      "bazar : 1\n",
      "noise_barrier : 1\n",
      "sewage : 1\n",
      "furniture : 1\n",
      "television : 1\n",
      "sundial : 1\n",
      "schwäbisch : 1\n",
      "MFG18 : 1\n",
      "Poliscan : 1\n",
      "cable_distribution_cabinet : 1\n",
      "parking_tickets : 1\n",
      "public_transport : 1\n",
      "woman : 1\n",
      "turkish : 1\n"
     ]
    }
   ],
   "source": [
    "def get_ways_and_nodes():\n",
    "    pipeline =  [{'$group' : { '_id' : '$type', 'count' : {'$sum' : 1}}},       \n",
    "                {'$sort': {'count': -1}}]\n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_ways_and_nodes()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Different Types:')\n",
    "pretty_print_list(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "There are a lot of rare types. In one next step, we could clean this up aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 amenities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities:\n",
      "restaurant : 1709\n",
      "bench : 1542\n",
      "cafe : 1005\n",
      "parking : 960\n",
      "fast_food : 723\n",
      "bicycle_parking : 623\n",
      "recycling : 580\n",
      "waste_basket : 578\n",
      "kindergarten : 572\n",
      "vending_machine : 499\n"
     ]
    }
   ],
   "source": [
    "def get_overview_amenities():\n",
    "    pipeline = [{'$match':{'amenity':{'$exists':1}}},\n",
    "                {'$group' : { '_id': '$amenity', 'count' : {'$sum':1}}},\n",
    "               {'$sort': {'count': -1}},\n",
    "               {'$limit': 10}]\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_overview_amenities()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Amenities:')\n",
    "pretty_print_list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Get number of bycicle roads**\n",
    "\n",
    "As we can see, there are 623 bycicle_parkings counted, which seems to be a lot. Because in Berlin there is currently a referndum  - https://volksentscheid-fahrrad.de/english/ - to make the city more bycicle friendly, we would like to take a closer look at the bycicle ways in the city.\n",
    "Because of the mixture of german and english there are different nodes to mark cicleways. http://wiki.openstreetmap.org/wiki/Key:bicycle_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roads:\n",
      "highway : 681059\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Bicycle Roads:\n",
      "secondary : 996\n",
      "primary : 529\n",
      "tertiary : 347\n",
      "residential : 195\n",
      "path : 66\n",
      "service : 20\n",
      "cycleway : 20\n",
      "pedestrian : 17\n",
      "footway : 6\n",
      "living_street : 6\n",
      "construction : 3\n",
      "None : 3\n",
      "secondary_link : 2\n",
      "primary_link : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Bicycle Roads Total:\n",
      "None : 2211\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Bicycle Roads Total - cleaned data:\n",
      "None : 5652\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "def get_roads():\n",
    "    pipeline = [{ '$group': {'_id': 'highway', 'count': {'$sum': 1}}}]\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_roads()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Roads:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~')       \n",
    "    \n",
    "#find bycicle roads in berlin\n",
    "def get_bicycle_roads():\n",
    "    pipeline = [{ '$match': {'$or':\n",
    "                    [{'bicycle': { '$in': ['official', 'designated', 'use_sidepath']}},\n",
    "                    {'bicycle_road': 'yes'},\n",
    "                    {'cycleway': {'$in': ['lane', 'opposite', 'shared', 'share_busway', 'track']}}]\n",
    "                    }},\n",
    "                {'$group' : { '_id': '$highway', 'count' : {'$sum':1}}},\n",
    "                {'$sort': {'count': -1}}]          \n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_bicycle_roads()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Bicycle Roads:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~')   \n",
    "\n",
    "def get_total_amount_of_cycleways():   \n",
    "    pipeline = [{ '$match': {'$or':\n",
    "                    [{'bicycle': { '$in': ['official', 'designated', 'use_sidepath']}},\n",
    "                    {'bicycle_road': 'yes'},\n",
    "                    {'cycleway': {'$in': ['lane', 'opposite', 'shared', 'share_busway', 'track']}}]\n",
    "                    }},\n",
    "                {'$group' : { '_id': None, 'count' : {'$sum':1}}}] \n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_total_amount_of_cycleways()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Bicycle Roads Total:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~')   \n",
    "\n",
    "def get_total_cycleways_with_cleaned_data():\n",
    "    pipeline = [{ '$match': {'bicycle_way': 'Yes'} },\n",
    "                {'$group' : { '_id': None, 'count' : {'$sum':1}}}] \n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_total_cycleways_with_cleaned_data()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Bicycle Roads Total - cleaned data:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the total number of highways, the number of bicycle roads in this map is extremly small\n",
    "It would be also interresting to calculate the length of all bicycle ways and compare them to the normal street net. \n",
    "The Query with the cleaned data for bicycles shows over fifty percent more entries. It seems that we missed some values for the different bicycles keys in the query for the osm data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hunger*\n",
    "Because Berlin is known for its masses of restaurants we want to take a closer look at the types of restaurants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants by cuisine:\n",
      "None : 1885\n",
      "italian : 265\n",
      "german : 117\n",
      "asian : 114\n",
      "kebab : 95\n",
      "burger : 90\n",
      "vietnamese : 84\n",
      "regional : 83\n",
      "indian : 81\n",
      "coffee_shop : 70\n",
      "pizza : 69\n"
     ]
    }
   ],
   "source": [
    "def get_overview_amenities():\n",
    "    pipeline = [{'$match': {'amenity': {'$exists': 1}, \n",
    "                            'amenity': {'$in': ['restaurant', 'fast_food', 'food_court', 'biergarten', 'bar', 'bbq', 'cafe'] \n",
    "                           }}},\n",
    "               {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},\n",
    "               {\"$sort\":{\"count\":-1}},\n",
    "               {\"$limit\": 11}]\n",
    "\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_overview_amenities()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Restaurants by cuisine:')\n",
    "pretty_print_list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional suggestions for improving and analyzing the data\n",
    "\n",
    "#### Length of bicycle ways and alles bio\n",
    "- it would be to calculate the length of all bycicley ways compared to the 'normal' street length. \n",
    "- It also would be interessting to calculate the the percentage of the surface types, because it is said that Berlin is a \"green\" city.\n",
    "\n",
    "#### Improve the dataset\n",
    "- Gamification would be a good way to encourage people to contribute more and correct data. For example games that are using geodata, like Pokemon Go or Geocaching,\n",
    "    could add functionality to the osm data. People could be attracted by leveling up or get other benefits for the game.  \n",
    "- Because nowadays google maps is very widely used and people can easily add amenities etc. via google, it would be great if that data could be merged into the OSM data.\n",
    "\n",
    "#### Potential problems\n",
    " - The language gap may be a problem. It may be that keys from different languages exist in one area, altough they mean the same. When doing analytics this can be missed out easily. \n",
    " - Missing or wrong data is a problem. This may skew findings in analytics or simply misslead people. http://maproulette.org/ could help to minor the problems.\n",
    " - Add totally wrong data in bad faith. As everone can add data to the OSM Project, it can happen that people add false data just for fun.\n",
    "\n",
    "## Conclusion\n",
    "The data set was cleaned, so that the language gap is bridged for our investigations. We could have cleaned out the data more, but as we want to have an basic overwiew, the cleaning amount is right. \n",
    "It is quite surprising that in a city where almost all inhabitants are \"super greenies\", the amount of bicycle ways is that small compared to the normal highways. It would be interesting to check the amount of bicycle ways in Amsterdam and compare it to Berlin.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
