{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** DA3 OPEN STREET MAP - DATA WRANGLING WITH MONGODB***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Map Area: Berlin, Germany*\n",
    "\n",
    "https://www.openstreetmap.org/#map=13/52.5180/13.4076\n",
    "\n",
    "The area contains the central area of Berlin. As it is one of the biggest cities in Europe, we can expect a lot of additional information about this area from the osm project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample of nodes in an .osm file:\n",
    "\n",
    "<node id=\"302864488\" visible=\"true\" version=\"7\" changeset=\"36059354\" timestamp=\"2015-12-20T06:35:42Z\" user=\"atpl_pilot\" uid=\"881429\" lat=\"52.5259586\" lon=\"13.3894424\">\n",
    "  <tag k=\"addr:city\" v=\"Berlin\"/>\n",
    "  <tag k=\"addr:country\" v=\"DE\"/>\n",
    "  <tag k=\"addr:housenumber\" v=\"45\"/>\n",
    "  <tag k=\"addr:postcode\" v=\"10117\"/>\n",
    "  <tag k=\"addr:street\" v=\"Oranienburger Straße\"/>\n",
    "  <tag k=\"addr:suburb\" v=\"Mitte\"/>\n",
    "  <tag k=\"amenity\" v=\"restaurant\"/>\n",
    "  <tag k=\"contact:phone\" v=\"+493028040505\"/>\n",
    "  <tag k=\"cuisine\" v=\"cuban\"/>\n",
    "  <tag k=\"name\" v=\"QBA\"/>\n",
    "  <tag k=\"website\" v=\"http://www.qba-restaurant.de/\"/>\n",
    "  <tag k=\"wheelchair\" v=\"no\"/>\n",
    " </node>\n",
    "\n",
    "<node id=\"270497666\" visible=\"true\" version=\"3\" changeset=\"21935727\" timestamp=\"2014-04-25T16:17:56Z\" user=\"HolgerJeromin\" uid=\"67862\" lat=\"52.5279489\" lon=\"13.3837052\">\n",
    "  <tag k=\"cemetery\" v=\"grave\"/>\n",
    "  <tag k=\"image\" v=\"http://commons.wikimedia.org/wiki/Image:Tombstone_Karl_Friedrich_Schinkel.jpg\"/>\n",
    "  <tag k=\"name\" v=\"Karl Friedrich Schinkel\"/>\n",
    "</node >\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. Size of File\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "#https://www.openstreetmap.org/export#map=13/52.5180/13.4076\n",
    "OSM_FILE = 'berlin_map.osm'\n",
    "SAMPLE_FILE = 'berlin_map_reduced.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSMSize 154.6 MB\n"
     ]
    }
   ],
   "source": [
    "#check file size\n",
    "#resource: http://stackoverflow.com/questions/2104080/how-to-check-file-size-in-python\n",
    "\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "\n",
    "\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "    \n",
    "size = file_size(OSM_FILE)\n",
    "print ('OSMSize', size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create sample file with the k - th size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berlin_map.osm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "k = 14 # Parameter: take every k-th top level element\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    b = bytearray()\n",
    "    b.extend('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'.encode())\n",
    "    b.extend('<osm>\\n  '.encode())\n",
    "    output.write(b)\n",
    "\n",
    "    # Write every kth top level element\n",
    "    print (OSM_FILE)\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "\n",
    "        if not i % k:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "    b_end = bytearray()\n",
    "    b_end.extend('</osm>'.encode())\n",
    "    output.write(b_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleSize 11.3 MB\n"
     ]
    }
   ],
   "source": [
    "#check size of sample file\n",
    "sample_size = file_size(SAMPLE_FILE)\n",
    "print ('SampleSize', sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDITING THE .OSM FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE USERS:  2003\n",
      "NODES: 594858\n",
      "WAYS: 86201\n",
      "RELATIONS 3203\n"
     ]
    }
   ],
   "source": [
    "#get benchmark data\n",
    "\"\"\"\n",
    "    Reference:\n",
    "    https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075462/lessons/768058569/concepts/8426285720923#\n",
    "\"\"\"\n",
    "def get_benchmark_data(filename):\n",
    "    users = set()\n",
    "    count_nodes = 0\n",
    "    count_ways = 0\n",
    "    count_relations = 0\n",
    "    \n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.tag == 'node':\n",
    "            count_nodes += 1\n",
    "            user = element.attrib['uid']\n",
    "            if user in users:\n",
    "                pass\n",
    "            else:\n",
    "                users.add(user)\n",
    "        if element.tag == 'way':\n",
    "            count_ways += 1\n",
    "        if element.tag == 'relation':\n",
    "            count_relations += 1\n",
    "    return users, count_nodes, count_ways, count_relations\n",
    "\n",
    "users, count_nodes, count_ways, count_relations = get_benchmark_data(OSM_FILE)\n",
    "\n",
    "print ('UNIQUE USERS: ', len(users))\n",
    "print ('NODES:', count_nodes)\n",
    "print ('WAYS:', count_ways)\n",
    "print ('RELATIONS', count_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUDIT STREET NAMES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problems encounterd while auditing street names:*\n",
    "\n",
    "   In German language there a lot of different namings and writings for streets: For example a 'Straße' can be 'Auerstraße' or     'Antwerpener Straße' or 'Alfred-Jung-Straße' or 'Straße des 17. Juni'. This happens also to other street types, like              '*weg*', '*zeile*', '*platz*' and also for streets that are or used to be near rivers like: '*damm*', '*ufer*', '*graben*'.\n",
    "   Because there a lot of bridges in Berlin, bridges belong to ways *brücke*. \n",
    "   A street name starting with 'Zur ', 'Am ' or 'An ' simply means 'at ', but is also a valid street name. \n",
    "    \n",
    "   Another problem is the case sensitiveness. Those key words may be written with uppercase or lowercase. In our case we simply    transform it to lowercase, to audit the street names. \n",
    "    \n",
    "   Another problem are the german Umlaute. Because we don't wan't to get troubled, instead of using regex, we will use a simple    loop to audit the street names.\n",
    "    \n",
    "   A further task would be to transform all Umlaute of the file at the beginning, to make sure not to get in trouble later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of different street types in Berlin\n",
      "Straße : 620\n",
      "Platz : 48\n",
      "Ufer : 28\n",
      "Allee : 18\n",
      "Damm : 12\n",
      "Weg : 9\n",
      "Am : 8\n",
      "Park : 6\n",
      "An : 5\n",
      "Brücke : 4\n",
      "Graben : 4\n",
      "Zeile : 3\n",
      "Promenade : 3\n",
      "Markt : 3\n",
      "Hof : 2\n",
      "Westring : 1\n",
      "Alt-Moabit : 1\n",
      "Fischerinsel : 1\n",
      "Prenzlauer Berg : 1\n",
      "Zur Waage : 1\n",
      "Stadtbahnbogen : 1\n",
      "Wriezener Karree : 1\n",
      "In Den Ministergärten : 1\n",
      "Steg : 1\n",
      "Südstern : 1\n",
      "Dohnagestell : 1\n",
      "Südring : 1\n",
      "Hinter Der Katholischen Kirche : 1\n",
      "Zur Innung : 1\n",
      "Fischzug : 1\n",
      "Großer Stern : 1\n",
      "Zur Börse : 1\n",
      "Unter Den Linden : 1\n",
      "Neue Welt : 1\n",
      "Südpassage : 1\n",
      "Vor Dem Schlesischen Tor : 1\n",
      "Alt-Stralau : 1\n",
      "Viehtrift : 1\n"
     ]
    }
   ],
   "source": [
    "'''reference:\n",
    "https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075462/lessons/768058569/concepts/8755386150923#'''\n",
    "\n",
    "#start with lower case letters, due to different ways of writing street names in german\n",
    "expected = ['straße', 'platz', 'gasse', 'weg', 'allee', 'damm', 'ufer', 'graben', 'brücke', \n",
    "            'promenade', 'park', 'am', 'an', 'markt', 'steg', 'hof', 'zeile']\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    found = False\n",
    "    for e in expected:\n",
    "        if e in street_name.lower():\n",
    "            found = True\n",
    "            break\n",
    "           \n",
    "    if found:\n",
    "        street_types[e].add(street_name)\n",
    "    else:\n",
    "        street_types[street_name.title()].add(street_name)    \n",
    "                              \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "#audit the street names\n",
    "def audit_street_names(osmfile):\n",
    "    osm_file = open(osmfile, 'rt', encoding='utf-8')\n",
    "    #set is a list without duplicates\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    print('Numbers of different street types in Berlin')\n",
    "    pretty_print(street_types)\n",
    "\n",
    "def pretty_print(d):\n",
    "    for sorted_key in sorted(d, key=lambda k: len(d[k]), reverse=True):\n",
    "        v = d[k]\n",
    "        print (sorted_key.title(), ':', len(d[sorted_key]))\n",
    "        \n",
    "audit_street_names(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It seems that all street names are valid!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audit Post codes and suburbs**\n",
    "The postal code in Berlin ranges from 10115 to 14199 \n",
    "In the following task we want to check if the postal code is valid for Berlin and if it matches with the suburb according to thist list : https://en.wikipedia.org/wiki/List_of_postal_codes_in_Germany#Berlin\n",
    "\n",
    "10115, 10117, 10119, 10178, 10179 - Berlin-Mitte\n",
    "10243, 10245, 10247, 10249 - Friedrichshain\n",
    "10318, 10319 - Lichtenberg\n",
    "10405, 10407, 10409, 10435, 10437, 10439 - Prenzlauer Berg\n",
    "10551, 10553, 10555, 10557, 10559 - Tiergarten\n",
    "10585, 10587, 10589, 10623, 10625, 10627, 10629 - Charlottenburg\n",
    "10707, 10709, 10711, 10713, 10715, 10719 - Wilmersdorf\n",
    "10777, 10779, 10781, 10783, 10789 - Tempelhof\n",
    "10823, 10825, 10827, 10829 - Schöneberg\n",
    "10961, 10963, 10965, 10967, 10969, 10997, 10999 - Kreuzberg\n",
    "12043, 12045, 12047, 12049, 12051, 12053, 12055, 12057, 12059 - Neukölln\n",
    "12157, 12161, 12163, 12165, 12167, 12169 - Steglitz\n",
    "12203, 12205, 12207, 12209 - Lichterfelde\n",
    "12247, 12249 - Lankwitz\n",
    "12277, 12279 - Marienfelde\n",
    "12305, 12307, 12309 - Lichtenrade\n",
    "12487, 12489 - Adlershof\n",
    "12555, 12557, 12559, 12587 - Köpenick\n",
    "12679, 12681, 12683, 12685, 12687, 12689 - Marzahn since 1979\n",
    "13086, 13088, 13089 - Weißensee\n",
    "13187, 13189 - Pankow\n",
    "13347, 13349, 13351, 13353, 13355, 13357, 13359 - Wedding\n",
    "13403, 13405, 13407, 13409 - Reinickendorf\n",
    "13435, 13437, 13439 - Wittenau\n",
    "14109 - Wannsee\n",
    "14163, 14165, 14167, 14169 - Zehlendorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-0ea96855774e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-0ea96855774e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    10115 to 14199\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TODO AUDIT Postal codes and suburbs\n",
    "10115 to 14199 \n",
    "\n",
    "expected_suburbs = ['Berlin-Mitte', 'Friedrichshain', 'Lichtenberg', 'Prenzlauer Berg', 'Tiergarten',\n",
    "                   'Charlottenburg', 'Wilmersdorf', 'Tempelhof', 'Schöneberg', 'Kreuzberg', 'Neukölln', \n",
    "                   'Steglitz', 'Lichterfelde', 'Lankwitz', 'Marienfelde', 'Lichtenrade',  'Adlershof',\n",
    "                   'Köpenick', 'Marzahn', 'Weißensee', 'Pankow','Wedding', 'Reinickendorf', 'Wittenau',\n",
    "                  'Wannsee', 'Zehlendorf']\n",
    "def audit_suburbs(expected_suburbs, suburb):\n",
    "    #TODO\n",
    "\n",
    "\n",
    "#check if postal code is correct and then check if it corresponds to correct suburbs\n",
    "def audit_postal_code(postal_range, postal_code):\n",
    "#TODO\n",
    "#TODO Check if postal code corresponds to correct suburb\n",
    "\n",
    "def is_postal_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def is_suburb(elem):\n",
    "    return (elem.attrib['k'] == \"addr:surbub\")\n",
    "\n",
    "#check if the postal_codes are correct\n",
    "#check if the postal code belongs to the right suburb\n",
    "def audit_postalcodes(osmfile):\n",
    "    osm_file = open(osmfile, 'rt', encoding='utf-8')\n",
    "    #set is a list without duplicates\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postal_code(tag):\n",
    "                    audit_postal_code(postal_codes, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    print('Postal Codes')\n",
    "    pretty_print(postal_codes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 2. transform to json\n",
    "''' \n",
    "reference:\n",
    "https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075462/lessons/768058569/concepts/8755386150923#'''\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "addr = re.compile(r'^([a-z]|_)*$')\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    created_dict = {}\n",
    "    pos_list = []\n",
    "    node_refs_list = []\n",
    "    long = 0\n",
    "    lat = 0\n",
    "\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        \n",
    "        node[\"type\"] = element.tag\n",
    "        for name, value in element.items():\n",
    "            if name in CREATED:\n",
    "                created_dict[name] = value\n",
    "            elif name == 'long':\n",
    "                lon = float(value)\n",
    "            elif name == 'lat':\n",
    "                lat = float(value)\n",
    "            else:\n",
    "                node[name] = value\n",
    "\n",
    "            if len(created_dict):\n",
    "                node[\"created\"] = created_dict\n",
    "            if lat:\n",
    "                pos_list.append(lat)\n",
    "            if long:\n",
    "                pos_list.append(long)\n",
    "            if len(pos_list):\n",
    "                node[\"pos\"] = pos_list\n",
    "\n",
    "        address = {}\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            k = tag.attrib['k']\n",
    "            v = tag.attrib['v']\n",
    "            if lower.search(k):\n",
    "                node[k] = v\n",
    "            elif lower_colon.search(k):\n",
    "                match = addr.search(k)\n",
    "\n",
    "                if match:\n",
    "                    if street_name(k):\n",
    "                        better_name = update_name(v, mapping)\n",
    "                        address[match.groups()[0]] = better_name\n",
    "                    else:\n",
    "                        address[match.groups()[0]] = v\n",
    "                elif problemchars.search(k):\n",
    "                    pass\n",
    "\n",
    "            if len(address):\n",
    "                node['address'] = address\n",
    "\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            node_refs_list.append(nd.attrib['ref'])\n",
    "            if len(node_refs_list):\n",
    "                node[\"node_refs\"] = node_refs_list\n",
    "                return node\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "#fix typos before exporting to mongodb\n",
    "mapping = { \"Str.\": \"Straße\",\n",
    "            \"Strase\": \"Straße\",\n",
    "            \"Strasse\": \"Straße\"}\n",
    "       \n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m.group() in mapping.keys():\n",
    "        match = re.search(street_type_re,name)\n",
    "        name = re.sub(street_type_re,mapping[match.group()],name)\n",
    "    if m.group() not in mapping.keys():\n",
    "        for ind in diction1:\n",
    "            if m.group() in diction1[ind]:\n",
    "                name = re.sub(m.group(), ind + ' ' + m.group(), name)\n",
    "    return name            \n",
    "            \n",
    "            \n",
    "def process_map(file_in):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "data = process_map('berlin_map.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show one element of the generated .json data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'postal_code': '10623', 'highway': 'primary', 'lanes': '3', 'surface': 'asphalt', 'ref': 'B 2;B 5', 'maxspeed': '50', 'created': {'version': '33', 'user': 'jacobbraeutigam', 'uid': '1260280', 'timestamp': '2016-06-12T20:13:17Z', 'changeset': '39978827'}, 'type': 'way', 'oneway': 'yes', 'lit': 'yes', 'name': 'Straße des 17. Juni', 'id': '4068038', 'node_refs': ['21487168']}\n"
     ]
    }
   ],
   "source": [
    "example = data[5]\n",
    "print (example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save data to mongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('587bd779c7993a1088b727ea'), 'type': 'way', 'maxspeed': '8', 'boat': 'yes', 'waterway': 'canal', 'have_riverbank': 'yes', 'id': '4041237', 'name': 'Landwehrkanal', 'draft': '1.40', 'node_refs': ['2087107436'], 'created': {'version': '17', 'user': 'Krille von Stralau', 'uid': '597190', 'timestamp': '2012-12-29T12:55:05Z', 'changeset': '14450125'}}\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "db = client.berlin\n",
    "\n",
    "def insert_osm_data(infile, db):\n",
    "    db.berlin.drop()      \n",
    "    #import data into a collection named \"berlin\"\n",
    "    db.berlin.insert_many(infile)\n",
    "    print (db.berlin.find_one())\n",
    "\n",
    "insert_osm_data(data, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50789\n"
     ]
    }
   ],
   "source": [
    "print (len(db.berlin.distinct(\"created\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get statistics of our database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataSize': 22989032.0, 'storageSize': 4096.0, 'objects': 86201, 'collections': 1, 'numExtents': 0, 'views': 0, 'avgObjSize': 266.69101286527996, 'indexes': 1, 'db': 'berlin', 'ok': 1.0, 'indexSize': 4096.0}\n"
     ]
    }
   ],
   "source": [
    "print (db.command(\"dbstats\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count ways**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86165"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.berlin.find({\"type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count unique users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188\n"
     ]
    }
   ],
   "source": [
    "print (len(db.berlin.distinct(\"created.user\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 contributiong users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 contributing users with counted entries:\n",
      "atpl_pilot : 20031\n",
      "anbr : 6537\n",
      "MorbZ : 5727\n",
      "Bot45715 : 3023\n",
      "Jojo4u : 2605\n",
      "Shmias : 2319\n",
      "Polarbear : 1999\n",
      "haytigran : 1859\n",
      "geozeisig : 1840\n",
      "RoterEmil : 1541\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_list(d):\n",
    "    for member in d:\n",
    "        print (member['_id'], ':', member['count'])    \n",
    "        \n",
    "# get top ten of contributing users\n",
    "def get_top_ten_users():\n",
    "    pipeline = [{'$group' : { '_id' : '$created.user', 'count' : {'$sum' : 1}}},       \n",
    "                {'$sort': {'count': -1}},\n",
    "                { '$limit': 10}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.berlin.aggregate(pipeline)]\n",
    "\n",
    "pipeline = get_top_ten_users()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Top 10 contributing users with counted entries:')\n",
    "pretty_print_list(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get an overview of different ways**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of ways with counted entries:\n",
      "way : 86165\n",
      "multipolygon : 29\n",
      "property_line : 4\n",
      "bazar : 1\n",
      "noise_barrier : 1\n",
      "sewage : 1\n"
     ]
    }
   ],
   "source": [
    "def get_overview_of_types():\n",
    "    pipeline =  [{'$group' : { '_id' : '$type', 'count' : {'$sum' : 1}}},       \n",
    "                {'$sort': {'count': -1}}]\n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_overview_of_types()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Types of ways with counted entries:')\n",
    "pretty_print_list(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get top 10 amenities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities:\n",
      "parking : 837\n",
      "school : 230\n",
      "kindergarten : 173\n",
      "place_of_worship : 119\n",
      "bicycle_parking : 98\n"
     ]
    }
   ],
   "source": [
    "def get_overview_amenities():\n",
    "    pipeline = [{'$match':{'amenity':{'$exists':1}}},\n",
    "                {'$group' : { '_id': '$amenity', 'count' : {'$sum':1}}},\n",
    "               {'$sort': {'count': -1}},\n",
    "               {'$limit': 5}]\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_overview_amenities()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Amenities:')\n",
    "pretty_print_list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Get number of bycicle roads**\n",
    "\n",
    "As we can see, there are 98 bycicle_parkings counted, which seems to be a lot. Because in Berlin there is currently a referndum  - https://volksentscheid-fahrrad.de/english/ - to make the city more bycicle friendly, we would like to take a closer look at the bycicle ways in the city.\n",
    "Because of the mixture of german and english there are different nodes to mark cicleways. http://wiki.openstreetmap.org/wiki/Key:bicycle_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roads:\n",
      "highway : 86201\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Bicycle Roads:\n",
      "secondary : 996\n",
      "primary : 529\n",
      "tertiary : 347\n",
      "residential : 195\n",
      "path : 66\n",
      "service : 20\n",
      "cycleway : 20\n",
      "pedestrian : 17\n",
      "footway : 6\n",
      "living_street : 6\n",
      "construction : 3\n",
      "secondary_link : 2\n",
      "primary_link : 1\n",
      "None : 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Bicycle Roads Total:\n",
      "None : 2209\n",
      "~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "def get_roads():\n",
    "    pipeline = [{ '$group': {'_id': 'highway', 'count': {'$sum': 1}}}]\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_roads()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Roads:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~')       \n",
    "    \n",
    "#find bycicle roads in berlin\n",
    "def get_bicycle_roads():\n",
    "    pipeline = [{ '$match': {'$or':\n",
    "                    [{'bicycle': { '$in': ['official', 'designated', 'use_sidepath']}},\n",
    "                    {'bicycle_road': 'yes'},\n",
    "                    {'cycleway': {'$in': ['lane', 'opposite', 'shared', 'share_busway', 'track']}}]\n",
    "                    }},\n",
    "                {'$group' : { '_id': '$highway', 'count' : {'$sum':1}}},\n",
    "                {'$sort': {'count': -1}}]          \n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_bicycle_roads()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Bicycle Roads:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~')   \n",
    "\n",
    "def get_total_amount_of_cycleways():   \n",
    "    pipeline = [{ '$match': {'$or':\n",
    "                    [{'bicycle': { '$in': ['official', 'designated', 'use_sidepath']}},\n",
    "                    {'bicycle_road': 'yes'},\n",
    "                    {'cycleway': {'$in': ['lane', 'opposite', 'shared', 'share_busway', 'track']}}]\n",
    "                    }},\n",
    "                {'$group' : { '_id': None, 'count' : {'$sum':1}}}] \n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_total_amount_of_cycleways()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Bicycle Roads Total:')\n",
    "pretty_print_list(result)\n",
    "print ('~~~~~~~~~~~~~~~~~~~~~~~')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the total number of highways, the number of bicycle roads in this map is extremly small\n",
    "It would be also interresting to calculate the length of all bicycle ways and compare them to the normal street net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hunger*\n",
    "\n",
    "Because Berlin is known for its masses of restaurants we want to take a closer look at the types of restaurants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants by cuisine:\n",
      "None : 89\n",
      "burger : 6\n",
      "regional : 5\n",
      "kebab : 5\n",
      "german : 5\n",
      "asian : 5\n",
      "donut : 2\n",
      "pizza : 2\n",
      "turkish : 2\n",
      "international : 1\n",
      "steak_house;fish : 1\n",
      "sushi : 1\n",
      "sandwich : 1\n",
      "american : 1\n",
      "greek : 1\n",
      "sausage : 1\n",
      "different : 1\n",
      "cuban : 1\n",
      "ice_cream : 1\n",
      "coffee_shop : 1\n",
      "arabian : 1\n",
      "spanish : 1\n",
      "vegetarian : 1\n",
      "ethiopian : 1\n",
      "regional,_national,_international : 1\n",
      "italian : 1\n",
      "Frühstück_Kaffee_&_Kuchen_Eis_Flohmarkt-Gelände : 1\n",
      "swiss : 1\n",
      "fish : 1\n",
      "bavarian : 1\n",
      "fish_and_chips : 1\n"
     ]
    }
   ],
   "source": [
    "def get_overview_amenities():\n",
    "    pipeline = [{'$match': {'amenity': {'$exists': 1}, \n",
    "                            'amenity': {'$in': ['restaurant', 'fast_food', 'food_court', 'biergarten', 'bar', 'bbq', 'cafe'] \n",
    "                           }}},\n",
    "               {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},\n",
    "               {\"$sort\":{\"count\":-1}}]\n",
    "\n",
    "    return pipeline\n",
    "    \n",
    "pipeline = get_overview_amenities()\n",
    "result = aggregate(db, pipeline)\n",
    "print ('Restaurants by cuisine:')\n",
    "pretty_print_list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "*problems encounterd*\n",
    "- The German Umlaute may cause problems, when we are using regex to audit files.\n",
    "- The German language has a lot of valid declarations for street names, so we have to audit it more often than english street names in order to make shure everything is valid.\n",
    "- The mixture between English and German words makes it a little bit more difficult to compare values. \n",
    "- There are different data-keys for bicycle-ways, so everything is mixed here.\n",
    "- When counting restaurants, it also shows that there is a mixture of languages. Which is shown with the entries 'coffee_shop' and '*Kaffee&Kuchen*', which is the same.\n",
    "- There is data missing, because there are far more restaurants in this area, than our query shows. \n",
    "\n",
    "*additional ideas*\n",
    "- Maybe it would be to calculate the length of all bycicley ways compared to the 'normal' street length. \n",
    "- It also would be interessting to calculate the the percentage of the surface types, because it is said that Berlin is a \"green\" city.\n",
    "- Maybe it would be nice, if there is an easier way to add data. So that more people, like tourists can add data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: \n",
    "- create pdf and html file for the analysis\n",
    "- create stand alone python file\n",
    "\n",
    "-\n",
    "Submission document includes one or more additional suggestions for improving and analyzing the data.\n",
    "One of the requirements of this project is to provide suggestions for improving and analyzing the data. Do not worry if the idea is difficult to implement or if it falls outside the scope of the project. We are just looking for innovative ways to improve the data. Following are some suggestions to get you started:\n",
    "\n",
    "Sample project has some good ideas: https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md\n",
    "How about using the popular game Pokemon Go to improve the dataset?\n",
    "Can we use third party tools like Google Maps API to improve the dataset?\n",
    "\n",
    "\n",
    "Submission document includes thoughtful discussion about the benefits as well as some anticipated problems in implementing the improvement.\n",
    "You are also required to include a discussion about the benefits as well as some anticipated problems in implementing the improvement. You can add two subsections as below:\n",
    "\n",
    "Benefits:\n",
    "\n",
    "point1\n",
    "point2\n",
    "\n",
    "Anticipated Problems:\n",
    "\n",
    "point1\n",
    "point2\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
